{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "miffy_or_kitty.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFxeXdeEptsT9M5e8j+9rT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielphil/fastai-sandbox/blob/master/lesson1/miffy_or_kitty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yRfxq6NUY2R",
        "colab_type": "text"
      },
      "source": [
        "This notebook will attempt to predict if an image contains Miffy or Hello Kitty. It uses your webcam, so no need to mess around with uploading images.\n",
        "\n",
        "No idea why I picked these subjects for a toy deep learning project, but I guess they look a little similar, so I thought it might be an interesting challenge for the network. ðŸ˜‰\n",
        "\n",
        "This was the result of following Lesson 1 of fast.ai's [Practical Deep Learning for Coders](https://course.fast.ai/) course.\n",
        "\n",
        "To run:\n",
        "* Select `Runtime->Run all` from the menu above.\n",
        "* Scroll to the bottom of the page. You should see a live display of your webcam.\n",
        "* Show some Miffy or Hello Kitty related images to the camera and the model will show the probabilities it thinks of your image being either Hello Kitty or Miffy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j56MFAzAUS16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# colab setup\n",
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "# download model\n",
        "!curl -o /content/models/export.pkl https://raw.githubusercontent.com/danielphil/fastai-sandbox/master/lesson1/export.pkl\n",
        "\n",
        "from fastai.vision import *\n",
        "defaults.device = torch.device('cpu')\n",
        "\n",
        "learn = load_learner('/content/models/')\n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "def Predict(b64_data):\n",
        "  filename = 'photo.jpg'\n",
        "  binary = b64decode(b64_data.split(',')[1])\n",
        "\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "\n",
        "  pred_class,pred_idx,outputs = learn.predict(open_image(filename))\n",
        "  result = \"\"\n",
        "  for i in range(len(outputs)):\n",
        "    result += '{}: {:.2f}%\\n'.format(learn.data.classes[i], outputs[i] * 100)\n",
        "\n",
        "  return IPython.display.JSON({'result': result})\n",
        "\n",
        "output.register_callback('notebook.Predict', Predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0KxhpO0VJro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%javascript\n",
        "const timeDelayMs = 1000\n",
        "\n",
        "async function captureAndPredict(textarea, video, status) {\n",
        "  const canvas = document.createElement('canvas');\n",
        "  canvas.width = video.videoWidth;\n",
        "  canvas.height = video.videoHeight;\n",
        "  canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "  imageData = canvas.toDataURL('image/jpeg', 0.8);\n",
        "\n",
        "  const result = await google.colab.kernel.invokeFunction(\n",
        "    'notebook.Predict', // The callback name.\n",
        "    [imageData], // The arguments.\n",
        "    {}); // kwargs\n",
        "\n",
        "  textarea.value = result.data['application/json'].result;\n",
        "\n",
        "  if (!status.done) {\n",
        "    setTimeout(() => captureAndPredict(textarea, video, status), timeDelayMs);\n",
        "  }\n",
        "}\n",
        "\n",
        "async function takePhoto(div) {\n",
        "  const stop = document.createElement('button');\n",
        "  const text = document.createElement('textarea');\n",
        "  text.textContent = \"Please wait...\"\n",
        "\n",
        "  stop.textContent = 'Stop';\n",
        "  div.appendChild(stop);\n",
        "  div.appendChild(text);\n",
        "\n",
        "  const video = document.createElement('video');\n",
        "  video.style.display = 'block';\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "  document.body.appendChild(div);\n",
        "  div.appendChild(video);\n",
        "  video.srcObject = stream;\n",
        "  await video.play();\n",
        "\n",
        "  // Resize the output to fit the video element.\n",
        "  google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "  var status = { done: false };\n",
        "\n",
        "  setTimeout(() => captureAndPredict(text, video, status), timeDelayMs)\n",
        "\n",
        "  // Wait for Done to be clicked.\n",
        "  await new Promise((resolve) => stop.onclick = resolve);\n",
        "\n",
        "  status.done = true;\n",
        "  stream.getVideoTracks()[0].stop();\n",
        "  div.remove();\n",
        "}\n",
        "\n",
        "(async function() {\n",
        "  const div = document.createElement('div');\n",
        "  document.querySelector(\"#output-area\").appendChild(div);\n",
        "  await takePhoto(div);\n",
        "})();"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}